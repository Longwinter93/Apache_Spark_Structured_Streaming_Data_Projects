{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "from IPython.display import display, clear_output\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,functions, Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.pandas as ps\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing .csv files. \n",
    "####  Spliting .csv file into a few ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>population_proper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>52.5167</td>\n",
       "      <td>13.3833</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>primary</td>\n",
       "      <td>3644826.0</td>\n",
       "      <td>3644826.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>53.5500</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>admin</td>\n",
       "      <td>1841179.0</td>\n",
       "      <td>1841179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Munich</td>\n",
       "      <td>48.1372</td>\n",
       "      <td>11.5755</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>admin</td>\n",
       "      <td>1471508.0</td>\n",
       "      <td>1471508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cologne</td>\n",
       "      <td>50.9422</td>\n",
       "      <td>6.9578</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>North Rhine-Westphalia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1085664.0</td>\n",
       "      <td>1085664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>50.1136</td>\n",
       "      <td>8.6797</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Hesse</td>\n",
       "      <td>minor</td>\n",
       "      <td>753056.0</td>\n",
       "      <td>753056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Rotenburg</td>\n",
       "      <td>53.0851</td>\n",
       "      <td>9.3879</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Lower Saxony</td>\n",
       "      <td>minor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>Karlstadt</td>\n",
       "      <td>49.9603</td>\n",
       "      <td>9.7724</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>minor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Neustadt</td>\n",
       "      <td>49.5656</td>\n",
       "      <td>8.8437</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Hesse</td>\n",
       "      <td>minor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>Homberg</td>\n",
       "      <td>51.0299</td>\n",
       "      <td>9.4026</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Hesse</td>\n",
       "      <td>minor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>Garmisch-Partenkirchen</td>\n",
       "      <td>47.4985</td>\n",
       "      <td>11.1044</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>minor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>612 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       city      lat      lng  country iso2  \\\n",
       "0                    Berlin  52.5167  13.3833  Germany   DE   \n",
       "1                   Hamburg  53.5500  10.0000  Germany   DE   \n",
       "2                    Munich  48.1372  11.5755  Germany   DE   \n",
       "3                   Cologne  50.9422   6.9578  Germany   DE   \n",
       "4                 Frankfurt  50.1136   8.6797  Germany   DE   \n",
       "..                      ...      ...      ...      ...  ...   \n",
       "607               Rotenburg  53.0851   9.3879  Germany   DE   \n",
       "608               Karlstadt  49.9603   9.7724  Germany   DE   \n",
       "609                Neustadt  49.5656   8.8437  Germany   DE   \n",
       "610                 Homberg  51.0299   9.4026  Germany   DE   \n",
       "611  Garmisch-Partenkirchen  47.4985  11.1044  Germany   DE   \n",
       "\n",
       "                 admin_name  capital  population  population_proper  \n",
       "0                    Berlin  primary   3644826.0          3644826.0  \n",
       "1                   Hamburg    admin   1841179.0          1841179.0  \n",
       "2                   Bavaria    admin   1471508.0          1471508.0  \n",
       "3    North Rhine-Westphalia      NaN   1085664.0          1085664.0  \n",
       "4                     Hesse    minor    753056.0           753056.0  \n",
       "..                      ...      ...         ...                ...  \n",
       "607            Lower Saxony    minor         NaN                NaN  \n",
       "608                 Bavaria    minor         NaN                NaN  \n",
       "609                   Hesse    minor         NaN                NaN  \n",
       "610                   Hesse    minor         NaN                NaN  \n",
       "611                 Bavaria    minor         NaN                NaN  \n",
       "\n",
       "[612 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ReadingCsvFile():\n",
    "    Path = r\"C:\\My projects\\Streaming_Data_Projects\\SparkStructuredStreaming_Project1\\Deutschland_Cities.csv\"\n",
    "    return pd.read_csv(Path)\n",
    "\n",
    "data = ReadingCsvFile()\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "size = 100\n",
    " \n",
    "for i in range(k):\n",
    "    df = data[size*i:size*(i+1)]\n",
    "    df.to_csv(f'Deutschland_Cities_{i+1}.csv', index=False)\n",
    "\n",
    "\n",
    "df_1 = pd.read_csv(\"Deutschland_Cities_1.csv\")\n",
    "df_1.to_csv('C:\\My projects\\Streaming_Data_Projects\\SparkStructuredStreaming_Project1\\InputStreamingData\\Deutschland_Cities_1.csv', \n",
    "            sep=',',index=False)\n",
    "\n",
    "df_2 = pd.read_csv(\"Deutschland_Cities_2.csv\")\n",
    "df_2.to_csv('C:\\My projects\\Streaming_Data_Projects\\SparkStructuredStreaming_Project1\\InputStreamingData\\Deutschland_Cities_2.csv', \n",
    "            sep=',',index=False)\n",
    "\n",
    "df_3 = pd.read_csv(\"Deutschland_Cities_3.csv\")\n",
    "df_3.to_csv('C:\\My projects\\Streaming_Data_Projects\\SparkStructuredStreaming_Project1\\InputStreamingData\\Deutschland_Cities_3.csv', \n",
    "            sep=',',index=False)\n",
    "\n",
    "df_4 = pd.read_csv(\"Deutschland_Cities_4.csv\")\n",
    "df_4.to_csv('C:\\My projects\\Streaming_Data_Projects\\SparkStructuredStreaming_Project1\\InputStreamingData\\InputStreamingData\\Deutschland_Cities_4.csv', \n",
    "            sep=',',index=False)\n",
    "\n",
    "df_5 = pd.read_csv(\"Deutschland_Cities_5.csv\")\n",
    "df_5.to_csv('C:\\My projects\\Streaming_Data_Projects\\SparkStructuredStreaming_Project1\\InputStreamingData\\InputStreamingData\\Deutschland_Cities_5.csv', \n",
    "            sep=',',index=False)\n",
    "\n",
    "df_6 = pd.read_csv(\"Deutschland_Cities_6.csv\")\n",
    "df_6.to_csv('C:\\My projects\\Streaming_Data_Projects\\SparkStructuredStreaming_Project1\\InputStreamingData\\InputStreamingData\\Deutschland_Cities_6.csv', \n",
    "            sep=',',index=False)\n",
    "\n",
    "df_7 = pd.read_csv(\"Deutschland_Cities_7.csv\")\n",
    "df_7.to_csv('C:\\My projects\\Streaming_Data_Projects\\SparkStructuredStreaming_Project1\\InputStreamingData\\InputStreamingData\\Deutschland_Cities_7.csv', \n",
    "            sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>population_proper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>52.5167</td>\n",
       "      <td>13.3833</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>primary</td>\n",
       "      <td>3644826.0</td>\n",
       "      <td>3644826.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>53.5500</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>admin</td>\n",
       "      <td>1841179.0</td>\n",
       "      <td>1841179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Munich</td>\n",
       "      <td>48.1372</td>\n",
       "      <td>11.5755</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>admin</td>\n",
       "      <td>1471508.0</td>\n",
       "      <td>1471508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cologne</td>\n",
       "      <td>50.9422</td>\n",
       "      <td>6.9578</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>North Rhine-Westphalia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1085664.0</td>\n",
       "      <td>1085664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>50.1136</td>\n",
       "      <td>8.6797</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Hesse</td>\n",
       "      <td>minor</td>\n",
       "      <td>753056.0</td>\n",
       "      <td>753056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Villingen-Schwenningen</td>\n",
       "      <td>48.0603</td>\n",
       "      <td>8.4586</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>minor</td>\n",
       "      <td>85181.0</td>\n",
       "      <td>85181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Konstanz</td>\n",
       "      <td>47.6633</td>\n",
       "      <td>9.1753</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84760.0</td>\n",
       "      <td>84760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Marl</td>\n",
       "      <td>51.6667</td>\n",
       "      <td>7.1167</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>North Rhine-Westphalia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83941.0</td>\n",
       "      <td>83941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Worms</td>\n",
       "      <td>49.6319</td>\n",
       "      <td>8.3653</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>Rhineland-Palatinate</td>\n",
       "      <td>minor</td>\n",
       "      <td>83330.0</td>\n",
       "      <td>83330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Velbert</td>\n",
       "      <td>51.3400</td>\n",
       "      <td>7.0416</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>North Rhine-Westphalia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81984.0</td>\n",
       "      <td>81984.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      city      lat      lng  country iso2  \\\n",
       "0                   Berlin  52.5167  13.3833  Germany   DE   \n",
       "1                  Hamburg  53.5500  10.0000  Germany   DE   \n",
       "2                   Munich  48.1372  11.5755  Germany   DE   \n",
       "3                  Cologne  50.9422   6.9578  Germany   DE   \n",
       "4                Frankfurt  50.1136   8.6797  Germany   DE   \n",
       "..                     ...      ...      ...      ...  ...   \n",
       "95  Villingen-Schwenningen  48.0603   8.4586  Germany   DE   \n",
       "96                Konstanz  47.6633   9.1753  Germany   DE   \n",
       "97                    Marl  51.6667   7.1167  Germany   DE   \n",
       "98                   Worms  49.6319   8.3653  Germany   DE   \n",
       "99                 Velbert  51.3400   7.0416  Germany   DE   \n",
       "\n",
       "                admin_name  capital  population  population_proper  \n",
       "0                   Berlin  primary   3644826.0          3644826.0  \n",
       "1                  Hamburg    admin   1841179.0          1841179.0  \n",
       "2                  Bavaria    admin   1471508.0          1471508.0  \n",
       "3   North Rhine-Westphalia      NaN   1085664.0          1085664.0  \n",
       "4                    Hesse    minor    753056.0           753056.0  \n",
       "..                     ...      ...         ...                ...  \n",
       "95       Baden-Württemberg    minor     85181.0            85181.0  \n",
       "96       Baden-Württemberg      NaN     84760.0            84760.0  \n",
       "97  North Rhine-Westphalia      NaN     83941.0            83941.0  \n",
       "98    Rhineland-Palatinate    minor     83330.0            83330.0  \n",
       "99  North Rhine-Westphalia      NaN     81984.0            81984.0  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating local SparkSession for Structured Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m SparkSession was successfully created\n"
     ]
    }
   ],
   "source": [
    "def CreateSparkSession():\n",
    "    try: \n",
    "        print(\"\\033[92m SparkSession was successfully created\")\n",
    "        spark = SparkSession.builder.appName(\"StructuredStreamingReadFromCsvfiles\").master('local[4]').getOrCreate() \n",
    "    except Exception:\n",
    "        print(\"\\033[91m SparkSession wasn't successfully created\")\n",
    "    return spark\n",
    "    \n",
    "spark = CreateSparkSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.14:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>StructuredStreamingReadFromCsvfiles</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x25e2b4c0f90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating streaming DataFrames and streaming Datasets\n",
    "####  Reading all csv files written atomically in a directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m DataFrame For Streaming Dataset was successfully created\n"
     ]
    }
   ],
   "source": [
    "def CreateDataFrameForStreamingDataSets():\n",
    "    try:\n",
    "        schema1 = StructType([StructField('city',StringType(), True),\n",
    "                        StructField('lat',DoubleType(), True),\n",
    "                        StructField('lng',DoubleType(), True),\n",
    "                        StructField('country',StringType(), True),\n",
    "                        StructField('iso2',StringType(), True),\n",
    "                        StructField('admin_name',StringType(), True),\n",
    "                        StructField('capital',StringType(), True),\n",
    "                        StructField('population',DoubleType(), True),\n",
    "                        StructField('population_proper',DoubleType(), True),])\n",
    "        LoadingPath = r\"C:\\My projects\\Streaming_Data_Projects\\SparkStructuredStreaming_Project1\\InputStreamingData\"\n",
    "        Deustchland = spark.readStream.format(\"csv\").schema(schema1)\\\n",
    "                        .option(\"header\",True).option(\"maxFilesPerTrigger\", 1)\\\n",
    "                        .load(LoadingPath)\n",
    "        print(\"\\033[92m DataFrame For Streaming Dataset was successfully created\")\n",
    "    except Exception:\n",
    "        print(\"\\033[91m DataFrame For Streaming Dataset wasn't successfully created\")\n",
    "    return Deustchland \n",
    "\n",
    "dfDeutschland = CreateDataFrameForStreamingDataSets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lng: double (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- iso2: string (nullable = true)\n",
      " |-- admin_name: string (nullable = true)\n",
      " |-- capital: string (nullable = true)\n",
      " |-- population: double (nullable = true)\n",
      " |-- population_proper: double (nullable = true)\n",
      "\n",
      "\u001b[92m The schema of the Streaming DataFrame was successfully created\n"
     ]
    }
   ],
   "source": [
    "def StreamingDataFrame():\n",
    "    try:\n",
    "        dfDeutschland.printSchema()\n",
    "        print(\"\\033[92m The schema of the Streaming DataFrame was successfully created\")\n",
    "    except Exception:\n",
    "        print(\"\\033[91m The schema of the Streaming DataFrame wasn't successfully created\")\n",
    "\n",
    "StreamingDataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying if this dataframe has streaming sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDeutschland.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing streaming data (DataFrame with no aggregations) to parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WritingStreamingData():\n",
    "    path = r\"C:\\My commercial projects\\Data Engineering Projects\\SparkStructuredStreaming_Project1\\OutputNoAgg\"\n",
    "    return  dfDeutschland.writeStream.format(\"parquet\")\\\n",
    "        .option(\"checkpointLocation\",path)\\\n",
    "        .option(\"path\",path)\\\n",
    "        .trigger(processingTime=\"1 second\").start()\n",
    "      \n",
    "NoAggdfDeutschland = WritingStreamingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Initializing sources',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Writing offsets to log',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Getting offsets from FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Writing offsets to log',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print('\\033[92m Status of the query')\n",
    "    display(NoAggdfDeutschland.status)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrame with aggregation\n",
    "#### Starting running the query and the output is stored in memory as an in-memory table\n",
    "##### Putting all the aggregates in an in-memory table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AggDataFrame():\n",
    "    dfDeutschlandAgg = dfDeutschland.groupBy(\"admin_name\").sum(\"population\")\n",
    "    return dfDeutschlandAgg.writeStream \\\n",
    "    .queryName(\"GroupingDeutschlandCityStreaming\") \\\n",
    "    .outputMode(\"complete\").format(\"memory\").start()\n",
    "\n",
    "AggdfDeustchland = AggDataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veryfing of active streaming queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active[0].isActive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying an in-memory table to look at streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Getting offsets from FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Writing offsets to log',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       304704.0|\n",
      "|       Saxony-Anhalt|       477954.0|\n",
      "|         Brandenburg|       278308.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      2942189.0|\n",
      "|Rhineland-Palatinate|       764078.0|\n",
      "|              Saxony|      1433277.0|\n",
      "|North Rhine-Westp...|      8977128.0|\n",
      "|           Thuringia|       408813.0|\n",
      "|        Lower Saxony|      1570208.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      1576759.0|\n",
      "|   Baden-Württemberg|      2589213.0|\n",
      "|            Saarland|       180741.0|\n",
      "|  Schleswig-Holstein|       554910.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       487593.0|\n",
      "|       Saxony-Anhalt|       559191.0|\n",
      "|         Brandenburg|       408305.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      3644496.0|\n",
      "|Rhineland-Palatinate|      1031687.0|\n",
      "|              Saxony|      1554532.0|\n",
      "|North Rhine-Westp...|    1.1518947E7|\n",
      "|           Thuringia|       473903.0|\n",
      "|        Lower Saxony|      2352377.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      1829398.0|\n",
      "|   Baden-Württemberg|      3370521.0|\n",
      "|            Saarland|       180741.0|\n",
      "|  Schleswig-Holstein|       763439.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Writing offsets to log',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       487593.0|\n",
      "|       Saxony-Anhalt|       559191.0|\n",
      "|         Brandenburg|       408305.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      3644496.0|\n",
      "|Rhineland-Palatinate|      1031687.0|\n",
      "|              Saxony|      1554532.0|\n",
      "|North Rhine-Westp...|    1.1518947E7|\n",
      "|           Thuringia|       473903.0|\n",
      "|        Lower Saxony|      2352377.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      1829398.0|\n",
      "|   Baden-Württemberg|      3370521.0|\n",
      "|            Saarland|       180741.0|\n",
      "|  Schleswig-Holstein|       763439.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       530143.0|\n",
      "|       Saxony-Anhalt|       725303.0|\n",
      "|         Brandenburg|       574232.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      4152496.0|\n",
      "|Rhineland-Palatinate|      1118767.0|\n",
      "|              Saxony|      1750246.0|\n",
      "|North Rhine-Westp...|    1.2795666E7|\n",
      "|           Thuringia|       679769.0|\n",
      "|        Lower Saxony|      2828297.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      2158029.0|\n",
      "|   Baden-Württemberg|      3958048.0|\n",
      "|            Saarland|       308395.0|\n",
      "|  Schleswig-Holstein|       806719.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Writing offsets to log',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       530143.0|\n",
      "|       Saxony-Anhalt|       725303.0|\n",
      "|         Brandenburg|       574232.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      4152496.0|\n",
      "|Rhineland-Palatinate|      1118767.0|\n",
      "|              Saxony|      1750246.0|\n",
      "|North Rhine-Westp...|    1.2795666E7|\n",
      "|           Thuringia|       679769.0|\n",
      "|        Lower Saxony|      2828297.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      2158029.0|\n",
      "|   Baden-Württemberg|      3958048.0|\n",
      "|            Saarland|       308395.0|\n",
      "|  Schleswig-Holstein|       806719.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       530143.0|\n",
      "|       Saxony-Anhalt|       725303.0|\n",
      "|         Brandenburg|       574232.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      4152496.0|\n",
      "|Rhineland-Palatinate|      1118767.0|\n",
      "|              Saxony|      1750246.0|\n",
      "|North Rhine-Westp...|    1.2795666E7|\n",
      "|           Thuringia|       679769.0|\n",
      "|        Lower Saxony|      2828297.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      2158029.0|\n",
      "|   Baden-Württemberg|      3958048.0|\n",
      "|            Saarland|       308395.0|\n",
      "|  Schleswig-Holstein|       806719.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Getting offsets from FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       559384.0|\n",
      "|       Saxony-Anhalt|       887912.0|\n",
      "|         Brandenburg|       666939.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      4306876.0|\n",
      "|Rhineland-Palatinate|      1218088.0|\n",
      "|              Saxony|      1846431.0|\n",
      "|North Rhine-Westp...|    1.3735348E7|\n",
      "|           Thuringia|       777500.0|\n",
      "|        Lower Saxony|      3347261.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      2513024.0|\n",
      "|   Baden-Württemberg|      4415320.0|\n",
      "|            Saarland|       408406.0|\n",
      "|  Schleswig-Holstein|       936168.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       559384.0|\n",
      "|       Saxony-Anhalt|       887912.0|\n",
      "|         Brandenburg|       666939.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      4306876.0|\n",
      "|Rhineland-Palatinate|      1218088.0|\n",
      "|              Saxony|      1846431.0|\n",
      "|North Rhine-Westp...|    1.3735348E7|\n",
      "|           Thuringia|       777500.0|\n",
      "|        Lower Saxony|      3347261.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      2513024.0|\n",
      "|   Baden-Württemberg|      4415320.0|\n",
      "|            Saarland|       408406.0|\n",
      "|  Schleswig-Holstein|       936168.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Writing offsets to log',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       559384.0|\n",
      "|       Saxony-Anhalt|       994769.0|\n",
      "|         Brandenburg|       846478.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      4600729.0|\n",
      "|Rhineland-Palatinate|      1300321.0|\n",
      "|              Saxony|      1952904.0|\n",
      "|North Rhine-Westp...|    1.4580071E7|\n",
      "|           Thuringia|       829919.0|\n",
      "|        Lower Saxony|      3476488.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      2800294.0|\n",
      "|   Baden-Württemberg|      4840873.0|\n",
      "|            Saarland|       434268.0|\n",
      "|  Schleswig-Holstein|      1042307.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       577421.0|\n",
      "|       Saxony-Anhalt|      1060149.0|\n",
      "|         Brandenburg|       952848.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      5167465.0|\n",
      "|Rhineland-Palatinate|      1452355.0|\n",
      "|              Saxony|      1992738.0|\n",
      "|North Rhine-Westp...|    1.4580071E7|\n",
      "|           Thuringia|      1029568.0|\n",
      "|        Lower Saxony|      3650983.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      2881998.0|\n",
      "|   Baden-Württemberg|      4981429.0|\n",
      "|            Saarland|       434268.0|\n",
      "|  Schleswig-Holstein|      1144953.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Writing offsets to log',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       577421.0|\n",
      "|       Saxony-Anhalt|      1060149.0|\n",
      "|         Brandenburg|       952848.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      5167465.0|\n",
      "|Rhineland-Palatinate|      1452355.0|\n",
      "|              Saxony|      1992738.0|\n",
      "|North Rhine-Westp...|    1.4580071E7|\n",
      "|           Thuringia|      1029568.0|\n",
      "|        Lower Saxony|      3650983.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      2881998.0|\n",
      "|   Baden-Württemberg|      4981429.0|\n",
      "|            Saarland|       434268.0|\n",
      "|  Schleswig-Holstein|      1144953.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       577421.0|\n",
      "|       Saxony-Anhalt|      1060149.0|\n",
      "|         Brandenburg|       952848.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      5167465.0|\n",
      "|Rhineland-Palatinate|      1452355.0|\n",
      "|              Saxony|      1992738.0|\n",
      "|North Rhine-Westp...|    1.4580071E7|\n",
      "|           Thuringia|      1029568.0|\n",
      "|        Lower Saxony|      3650983.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      2881998.0|\n",
      "|   Baden-Württemberg|      4981429.0|\n",
      "|            Saarland|       434268.0|\n",
      "|  Schleswig-Holstein|      1144953.0|\n",
      "+--------------------+---------------+\n",
      "\n",
      "\u001b[93m Status of the query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Getting offsets from FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m Watching continuously updated results\n",
      "+--------------------+---------------+\n",
      "|          admin_name|sum(population)|\n",
      "+--------------------+---------------+\n",
      "|Mecklenburg-Weste...|       577421.0|\n",
      "|       Saxony-Anhalt|      1060149.0|\n",
      "|         Brandenburg|       952848.0|\n",
      "|              Berlin|      3644826.0|\n",
      "|             Bavaria|      5167465.0|\n",
      "|Rhineland-Palatinate|      1463072.0|\n",
      "|              Saxony|      1992738.0|\n",
      "|North Rhine-Westp...|    1.4580071E7|\n",
      "|           Thuringia|      1029568.0|\n",
      "|        Lower Saxony|      3650983.0|\n",
      "|             Hamburg|      1841179.0|\n",
      "|              Bremen|       838543.0|\n",
      "|               Hesse|      2881998.0|\n",
      "|   Baden-Württemberg|      4981429.0|\n",
      "|            Saarland|       434268.0|\n",
      "|  Schleswig-Holstein|      1144953.0|\n",
      "+--------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def InMemoryTable():\n",
    "    for x in range(15):\n",
    "        print('\\033[93m Status of the query')\n",
    "        display(AggdfDeustchland.status)\n",
    "        print('\\033[95m Watching continuously updated results')\n",
    "        df = spark.sql(\"select * from GroupingDeutschlandCityStreaming\")\n",
    "        if df.count() > 0:\n",
    "            df.show()\n",
    "        time.sleep(1)\n",
    "\n",
    "InMemoryTable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final result of output sink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+---------------+\n",
      "|admin_name                   |sum(population)|\n",
      "+-----------------------------+---------------+\n",
      "|Mecklenburg-Western Pomerania|577421.0       |\n",
      "|Saxony-Anhalt                |1060149.0      |\n",
      "|Brandenburg                  |952848.0       |\n",
      "|Berlin                       |3644826.0      |\n",
      "|Bavaria                      |5167465.0      |\n",
      "|Rhineland-Palatinate         |1463072.0      |\n",
      "|Saxony                       |1992738.0      |\n",
      "|North Rhine-Westphalia       |1.4580071E7    |\n",
      "|Thuringia                    |1029568.0      |\n",
      "|Lower Saxony                 |3650983.0      |\n",
      "|Hamburg                      |1841179.0      |\n",
      "|Bremen                       |838543.0       |\n",
      "|Hesse                        |2881998.0      |\n",
      "|Baden-Württemberg            |4981429.0      |\n",
      "|Saarland                     |434268.0       |\n",
      "|Schleswig-Holstein           |1144953.0      |\n",
      "+-----------------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ResultOfOutput():\n",
    "    spark.sql(\"select * from GroupingDeutschlandCityStreaming\").show(truncate=False) \n",
    "\n",
    "ResultOfOutput()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying an in-memory table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------------------+-----------+\n",
      "|namespace|tableName                       |isTemporary|\n",
      "+---------+--------------------------------+-----------+\n",
      "|         |groupingdeutschlandcitystreaming|true       |\n",
      "+---------+--------------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def DisplayInMemoryTable():\n",
    "    spark.sql('show tables').show(truncate=False)\n",
    "\n",
    "DisplayInMemoryTable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrame based on an in-memory table and save this data to parquet and json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+---------------+\n",
      "|admin_name                   |sum(population)|\n",
      "+-----------------------------+---------------+\n",
      "|Mecklenburg-Western Pomerania|577421.0       |\n",
      "|Saxony-Anhalt                |1060149.0      |\n",
      "|Brandenburg                  |952848.0       |\n",
      "|Berlin                       |3644826.0      |\n",
      "|Bavaria                      |5167465.0      |\n",
      "|Rhineland-Palatinate         |1463072.0      |\n",
      "|Saxony                       |1992738.0      |\n",
      "|North Rhine-Westphalia       |1.4580071E7    |\n",
      "|Thuringia                    |1029568.0      |\n",
      "|Lower Saxony                 |3650983.0      |\n",
      "|Hamburg                      |1841179.0      |\n",
      "|Bremen                       |838543.0       |\n",
      "|Hesse                        |2881998.0      |\n",
      "|Baden-Württemberg            |4981429.0      |\n",
      "|Saarland                     |434268.0       |\n",
      "|Schleswig-Holstein           |1144953.0      |\n",
      "+-----------------------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dlugo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def CreateDataFrameBasedOnInMemoryTable():\n",
    "    sqlContext = SQLContext(spark)\n",
    "    df=sqlContext.sql(\"select * from GroupingDeutschlandCityStreaming\")\n",
    "    return df \n",
    "\n",
    "df = CreateDataFrameBasedOnInMemoryTable()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m DataFrame was successfully saved to JSON and parquet files\n"
     ]
    }
   ],
   "source": [
    "def SavingToJsonParquetFiles():\n",
    "    try:\n",
    "        df.coalesce(1).write.mode(\"overwrite\").parquet(\"GroupingDeutschlandCityStreaming.parquet\")\n",
    "        df.coalesce(1).write.mode(\"overwrite\").json(\"GroupingDeutschlandCityStreaming.json\")\n",
    "        print(\"\\033[92m DataFrame was successfully saved to JSON and parquet files\")\n",
    "    except Exception:\n",
    "        print(\"\\033[91m DataFrame wasn't successfully saved to JSON and parquet files\")\n",
    "\n",
    "SavingToJsonParquetFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active[0].isActive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Streaming Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m Managing Streaming Queries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(([{'id': '1dd2f6ca-8900-434c-8b04-e4edb656da4f',\n",
       "    'runId': 'bbf01bdb-9af7-4d4f-9033-8747473d9e78',\n",
       "    'name': 'GroupingDeutschlandCityStreaming',\n",
       "    'timestamp': '2023-10-13T07:29:59.214Z',\n",
       "    'batchId': 0,\n",
       "    'numInputRows': 100,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 4.837695321948623,\n",
       "    'durationMs': {'addBatch': 19500,\n",
       "     'commitOffsets': 339,\n",
       "     'getBatch': 0,\n",
       "     'latestOffset': 384,\n",
       "     'queryPlanning': 82,\n",
       "     'triggerExecution': 20671,\n",
       "     'walCommit': 366},\n",
       "    'stateOperators': [{'operatorName': 'stateStoreSave',\n",
       "      'numRowsTotal': 16,\n",
       "      'numRowsUpdated': 16,\n",
       "      'allUpdatesTimeMs': 715,\n",
       "      'numRowsRemoved': 0,\n",
       "      'allRemovalsTimeMs': 0,\n",
       "      'commitTimeMs': 67834,\n",
       "      'memoryUsedBytes': 49144,\n",
       "      'numRowsDroppedByWatermark': 0,\n",
       "      'numShufflePartitions': 200,\n",
       "      'numStateStoreInstances': 200,\n",
       "      'customMetrics': {'loadedMapCacheHitCount': 0,\n",
       "       'loadedMapCacheMissCount': 0,\n",
       "       'stateOnCurrentVersionSizeBytes': 20344}}],\n",
       "    'sources': [{'description': 'FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       "      'startOffset': None,\n",
       "      'endOffset': {'logOffset': 0},\n",
       "      'latestOffset': None,\n",
       "      'numInputRows': 100,\n",
       "      'inputRowsPerSecond': 0.0,\n",
       "      'processedRowsPerSecond': 4.837695321948623}],\n",
       "    'sink': {'description': 'MemorySink', 'numOutputRows': 16}},\n",
       "   {'id': '1dd2f6ca-8900-434c-8b04-e4edb656da4f',\n",
       "    'runId': 'bbf01bdb-9af7-4d4f-9033-8747473d9e78',\n",
       "    'name': 'GroupingDeutschlandCityStreaming',\n",
       "    'timestamp': '2023-10-13T07:30:19.888Z',\n",
       "    'batchId': 1,\n",
       "    'numInputRows': 100,\n",
       "    'inputRowsPerSecond': 4.836993324949212,\n",
       "    'processedRowsPerSecond': 4.245202920699609,\n",
       "    'durationMs': {'addBatch': 22423,\n",
       "     'commitOffsets': 431,\n",
       "     'getBatch': 6,\n",
       "     'latestOffset': 310,\n",
       "     'queryPlanning': 13,\n",
       "     'triggerExecution': 23556,\n",
       "     'walCommit': 372},\n",
       "    'stateOperators': [{'operatorName': 'stateStoreSave',\n",
       "      'numRowsTotal': 16,\n",
       "      'numRowsUpdated': 12,\n",
       "      'allUpdatesTimeMs': 409,\n",
       "      'numRowsRemoved': 0,\n",
       "      'allRemovalsTimeMs': 0,\n",
       "      'commitTimeMs': 85106,\n",
       "      'memoryUsedBytes': 87320,\n",
       "      'numRowsDroppedByWatermark': 0,\n",
       "      'numShufflePartitions': 200,\n",
       "      'numStateStoreInstances': 200,\n",
       "      'customMetrics': {'loadedMapCacheHitCount': 400,\n",
       "       'loadedMapCacheMissCount': 0,\n",
       "       'stateOnCurrentVersionSizeBytes': 23864}}],\n",
       "    'sources': [{'description': 'FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       "      'startOffset': {'logOffset': 0},\n",
       "      'endOffset': {'logOffset': 1},\n",
       "      'latestOffset': None,\n",
       "      'numInputRows': 100,\n",
       "      'inputRowsPerSecond': 4.836993324949212,\n",
       "      'processedRowsPerSecond': 4.245202920699609}],\n",
       "    'sink': {'description': 'MemorySink', 'numOutputRows': 16}},\n",
       "   {'id': '1dd2f6ca-8900-434c-8b04-e4edb656da4f',\n",
       "    'runId': 'bbf01bdb-9af7-4d4f-9033-8747473d9e78',\n",
       "    'name': 'GroupingDeutschlandCityStreaming',\n",
       "    'timestamp': '2023-10-13T07:30:43.445Z',\n",
       "    'batchId': 2,\n",
       "    'numInputRows': 100,\n",
       "    'inputRowsPerSecond': 4.2450227108715035,\n",
       "    'processedRowsPerSecond': 4.281738385784628,\n",
       "    'durationMs': {'addBatch': 22100,\n",
       "     'commitOffsets': 431,\n",
       "     'getBatch': 8,\n",
       "     'latestOffset': 421,\n",
       "     'queryPlanning': 9,\n",
       "     'triggerExecution': 23355,\n",
       "     'walCommit': 385},\n",
       "    'stateOperators': [{'operatorName': 'stateStoreSave',\n",
       "      'numRowsTotal': 16,\n",
       "      'numRowsUpdated': 13,\n",
       "      'allUpdatesTimeMs': 188,\n",
       "      'numRowsRemoved': 0,\n",
       "      'allRemovalsTimeMs': 0,\n",
       "      'commitTimeMs': 84761,\n",
       "      'memoryUsedBytes': 90912,\n",
       "      'numRowsDroppedByWatermark': 0,\n",
       "      'numShufflePartitions': 200,\n",
       "      'numStateStoreInstances': 200,\n",
       "      'customMetrics': {'loadedMapCacheHitCount': 800,\n",
       "       'loadedMapCacheMissCount': 0,\n",
       "       'stateOnCurrentVersionSizeBytes': 23864}}],\n",
       "    'sources': [{'description': 'FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       "      'startOffset': {'logOffset': 1},\n",
       "      'endOffset': {'logOffset': 2},\n",
       "      'latestOffset': None,\n",
       "      'numInputRows': 100,\n",
       "      'inputRowsPerSecond': 4.2450227108715035,\n",
       "      'processedRowsPerSecond': 4.281738385784628}],\n",
       "    'sink': {'description': 'MemorySink', 'numOutputRows': 16}},\n",
       "   {'id': '1dd2f6ca-8900-434c-8b04-e4edb656da4f',\n",
       "    'runId': 'bbf01bdb-9af7-4d4f-9033-8747473d9e78',\n",
       "    'name': 'GroupingDeutschlandCityStreaming',\n",
       "    'timestamp': '2023-10-13T07:31:06.801Z',\n",
       "    'batchId': 3,\n",
       "    'numInputRows': 100,\n",
       "    'inputRowsPerSecond': 4.281555060798081,\n",
       "    'processedRowsPerSecond': 3.5257201283362125,\n",
       "    'durationMs': {'addBatch': 27120,\n",
       "     'commitOffsets': 455,\n",
       "     'getBatch': 7,\n",
       "     'latestOffset': 362,\n",
       "     'queryPlanning': 8,\n",
       "     'triggerExecution': 28363,\n",
       "     'walCommit': 410},\n",
       "    'stateOperators': [{'operatorName': 'stateStoreSave',\n",
       "      'numRowsTotal': 16,\n",
       "      'numRowsUpdated': 13,\n",
       "      'allUpdatesTimeMs': 318,\n",
       "      'numRowsRemoved': 0,\n",
       "      'allRemovalsTimeMs': 0,\n",
       "      'commitTimeMs': 103693,\n",
       "      'memoryUsedBytes': 90912,\n",
       "      'numRowsDroppedByWatermark': 0,\n",
       "      'numShufflePartitions': 200,\n",
       "      'numStateStoreInstances': 200,\n",
       "      'customMetrics': {'loadedMapCacheHitCount': 1200,\n",
       "       'loadedMapCacheMissCount': 0,\n",
       "       'stateOnCurrentVersionSizeBytes': 23864}}],\n",
       "    'sources': [{'description': 'FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       "      'startOffset': {'logOffset': 2},\n",
       "      'endOffset': {'logOffset': 3},\n",
       "      'latestOffset': None,\n",
       "      'numInputRows': 100,\n",
       "      'inputRowsPerSecond': 4.281555060798081,\n",
       "      'processedRowsPerSecond': 3.5257201283362125}],\n",
       "    'sink': {'description': 'MemorySink', 'numOutputRows': 16}},\n",
       "   {'id': '1dd2f6ca-8900-434c-8b04-e4edb656da4f',\n",
       "    'runId': 'bbf01bdb-9af7-4d4f-9033-8747473d9e78',\n",
       "    'name': 'GroupingDeutschlandCityStreaming',\n",
       "    'timestamp': '2023-10-13T07:31:35.167Z',\n",
       "    'batchId': 4,\n",
       "    'numInputRows': 100,\n",
       "    'inputRowsPerSecond': 3.5253472467038005,\n",
       "    'processedRowsPerSecond': 3.629500580720093,\n",
       "    'durationMs': {'addBatch': 26125,\n",
       "     'commitOffsets': 386,\n",
       "     'getBatch': 24,\n",
       "     'latestOffset': 489,\n",
       "     'queryPlanning': 35,\n",
       "     'triggerExecution': 27552,\n",
       "     'walCommit': 490},\n",
       "    'stateOperators': [{'operatorName': 'stateStoreSave',\n",
       "      'numRowsTotal': 16,\n",
       "      'numRowsUpdated': 12,\n",
       "      'allUpdatesTimeMs': 360,\n",
       "      'numRowsRemoved': 0,\n",
       "      'allRemovalsTimeMs': 0,\n",
       "      'commitTimeMs': 99010,\n",
       "      'memoryUsedBytes': 90840,\n",
       "      'numRowsDroppedByWatermark': 0,\n",
       "      'numShufflePartitions': 200,\n",
       "      'numStateStoreInstances': 200,\n",
       "      'customMetrics': {'loadedMapCacheHitCount': 1600,\n",
       "       'loadedMapCacheMissCount': 0,\n",
       "       'stateOnCurrentVersionSizeBytes': 23864}}],\n",
       "    'sources': [{'description': 'FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       "      'startOffset': {'logOffset': 3},\n",
       "      'endOffset': {'logOffset': 4},\n",
       "      'latestOffset': None,\n",
       "      'numInputRows': 100,\n",
       "      'inputRowsPerSecond': 3.5253472467038005,\n",
       "      'processedRowsPerSecond': 3.629500580720093}],\n",
       "    'sink': {'description': 'MemorySink', 'numOutputRows': 16}},\n",
       "   {'id': '1dd2f6ca-8900-434c-8b04-e4edb656da4f',\n",
       "    'runId': 'bbf01bdb-9af7-4d4f-9033-8747473d9e78',\n",
       "    'name': 'GroupingDeutschlandCityStreaming',\n",
       "    'timestamp': '2023-10-13T07:32:02.721Z',\n",
       "    'batchId': 5,\n",
       "    'numInputRows': 100,\n",
       "    'inputRowsPerSecond': 3.629237134354359,\n",
       "    'processedRowsPerSecond': 3.698498409645684,\n",
       "    'durationMs': {'addBatch': 25762,\n",
       "     'commitOffsets': 520,\n",
       "     'getBatch': 10,\n",
       "     'latestOffset': 362,\n",
       "     'queryPlanning': 29,\n",
       "     'triggerExecution': 27038,\n",
       "     'walCommit': 353},\n",
       "    'stateOperators': [{'operatorName': 'stateStoreSave',\n",
       "      'numRowsTotal': 16,\n",
       "      'numRowsUpdated': 11,\n",
       "      'allUpdatesTimeMs': 320,\n",
       "      'numRowsRemoved': 0,\n",
       "      'allRemovalsTimeMs': 0,\n",
       "      'commitTimeMs': 98841,\n",
       "      'memoryUsedBytes': 90768,\n",
       "      'numRowsDroppedByWatermark': 0,\n",
       "      'numShufflePartitions': 200,\n",
       "      'numStateStoreInstances': 200,\n",
       "      'customMetrics': {'loadedMapCacheHitCount': 2000,\n",
       "       'loadedMapCacheMissCount': 0,\n",
       "       'stateOnCurrentVersionSizeBytes': 23864}}],\n",
       "    'sources': [{'description': 'FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       "      'startOffset': {'logOffset': 4},\n",
       "      'endOffset': {'logOffset': 5},\n",
       "      'latestOffset': None,\n",
       "      'numInputRows': 100,\n",
       "      'inputRowsPerSecond': 3.629237134354359,\n",
       "      'processedRowsPerSecond': 3.698498409645684}],\n",
       "    'sink': {'description': 'MemorySink', 'numOutputRows': 16}},\n",
       "   {'id': '1dd2f6ca-8900-434c-8b04-e4edb656da4f',\n",
       "    'runId': 'bbf01bdb-9af7-4d4f-9033-8747473d9e78',\n",
       "    'name': 'GroupingDeutschlandCityStreaming',\n",
       "    'timestamp': '2023-10-13T07:32:29.763Z',\n",
       "    'batchId': 6,\n",
       "    'numInputRows': 12,\n",
       "    'inputRowsPerSecond': 0.4437541601952518,\n",
       "    'processedRowsPerSecond': 0.49908501081350853,\n",
       "    'durationMs': {'addBatch': 22484,\n",
       "     'commitOffsets': 466,\n",
       "     'getBatch': 8,\n",
       "     'latestOffset': 569,\n",
       "     'queryPlanning': 14,\n",
       "     'triggerExecution': 24044,\n",
       "     'walCommit': 503},\n",
       "    'stateOperators': [{'operatorName': 'stateStoreSave',\n",
       "      'numRowsTotal': 16,\n",
       "      'numRowsUpdated': 5,\n",
       "      'allUpdatesTimeMs': 203,\n",
       "      'numRowsRemoved': 0,\n",
       "      'allRemovalsTimeMs': 0,\n",
       "      'commitTimeMs': 86135,\n",
       "      'memoryUsedBytes': 90336,\n",
       "      'numRowsDroppedByWatermark': 0,\n",
       "      'numShufflePartitions': 200,\n",
       "      'numStateStoreInstances': 200,\n",
       "      'customMetrics': {'loadedMapCacheHitCount': 2400,\n",
       "       'loadedMapCacheMissCount': 0,\n",
       "       'stateOnCurrentVersionSizeBytes': 23864}}],\n",
       "    'sources': [{'description': 'FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       "      'startOffset': {'logOffset': 5},\n",
       "      'endOffset': {'logOffset': 6},\n",
       "      'latestOffset': None,\n",
       "      'numInputRows': 12,\n",
       "      'inputRowsPerSecond': 0.4437541601952518,\n",
       "      'processedRowsPerSecond': 0.49908501081350853}],\n",
       "    'sink': {'description': 'MemorySink', 'numOutputRows': 16}}],),\n",
       " {'id': '1dd2f6ca-8900-434c-8b04-e4edb656da4f',\n",
       "  'runId': 'bbf01bdb-9af7-4d4f-9033-8747473d9e78',\n",
       "  'name': 'GroupingDeutschlandCityStreaming',\n",
       "  'timestamp': '2023-10-13T07:32:29.763Z',\n",
       "  'batchId': 6,\n",
       "  'numInputRows': 12,\n",
       "  'inputRowsPerSecond': 0.4437541601952518,\n",
       "  'processedRowsPerSecond': 0.49908501081350853,\n",
       "  'durationMs': {'addBatch': 22484,\n",
       "   'commitOffsets': 466,\n",
       "   'getBatch': 8,\n",
       "   'latestOffset': 569,\n",
       "   'queryPlanning': 14,\n",
       "   'triggerExecution': 24044,\n",
       "   'walCommit': 503},\n",
       "  'stateOperators': [{'operatorName': 'stateStoreSave',\n",
       "    'numRowsTotal': 16,\n",
       "    'numRowsUpdated': 5,\n",
       "    'allUpdatesTimeMs': 203,\n",
       "    'numRowsRemoved': 0,\n",
       "    'allRemovalsTimeMs': 0,\n",
       "    'commitTimeMs': 86135,\n",
       "    'memoryUsedBytes': 90336,\n",
       "    'numRowsDroppedByWatermark': 0,\n",
       "    'numShufflePartitions': 200,\n",
       "    'numStateStoreInstances': 200,\n",
       "    'customMetrics': {'loadedMapCacheHitCount': 2400,\n",
       "     'loadedMapCacheMissCount': 0,\n",
       "     'stateOnCurrentVersionSizeBytes': 23864}}],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/My commercial projects/Data Engineering Projects/SparkStructuredStreaming_Project1/InputStreamingData]',\n",
       "    'startOffset': {'logOffset': 5},\n",
       "    'endOffset': {'logOffset': 6},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 12,\n",
       "    'inputRowsPerSecond': 0.4437541601952518,\n",
       "    'processedRowsPerSecond': 0.49908501081350853}],\n",
       "  'sink': {'description': 'MemorySink', 'numOutputRows': 16}},\n",
       " 'GroupingDeutschlandCityStreaming',\n",
       " <bound method StreamingQuery.explain of <pyspark.sql.streaming.query.StreamingQuery object at 0x0000025E2B4D3B90>>,\n",
       " {'message': 'Waiting for data to arrive',\n",
       "  'isDataAvailable': False,\n",
       "  'isTriggerActive': False},\n",
       " {'message': 'Waiting for next trigger',\n",
       "  'isDataAvailable': False,\n",
       "  'isTriggerActive': False})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ManagingStreamingQueries():\n",
    "    print(\"\\033[94m Managing Streaming Queries\")\n",
    "    recentProgress = AggdfDeustchland.recentProgress,\n",
    "    lastProgress = AggdfDeustchland.lastProgress\n",
    "    name = AggdfDeustchland.name\n",
    "    explain = AggdfDeustchland.explain\n",
    "    statusAggdf = AggdfDeustchland.status\n",
    "    statusNoAggdf = NoAggdfDeutschland.status\n",
    "    return recentProgress, lastProgress, name, explain, statusAggdf,statusNoAggdf\n",
    "\n",
    "ManagingStreamingQueries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Stopping` queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m Stopping queries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " {'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False},\n",
       " None,\n",
       " {'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def StopQueries():\n",
    "    print(\"\\033[91m Stopping queries\")\n",
    "    stopAggdf = AggdfDeustchland.stop()\n",
    "    statusAggdf = AggdfDeustchland.status\n",
    "    stopNoAggdf = NoAggdfDeutschland.stop()\n",
    "    statusNoAggdf = NoAggdfDeutschland.status\n",
    "    return stopAggdf, statusAggdf, stopNoAggdf, statusNoAggdf\n",
    "    \n",
    "StopQueries()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
